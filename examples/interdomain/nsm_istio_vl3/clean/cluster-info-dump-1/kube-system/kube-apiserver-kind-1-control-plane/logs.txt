==== START logs for container kube-apiserver of pod kube-system/kube-apiserver-kind-1-control-plane ====
I1221 04:30:57.583232       1 server.go:563] external host was not specified, using 172.18.0.2
I1221 04:30:57.583818       1 server.go:161] Version: v1.25.3
I1221 04:30:57.583927       1 server.go:163] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I1221 04:30:57.808832       1 plugins.go:158] Loaded 12 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,MutatingAdmissionWebhook.
I1221 04:30:57.808850       1 plugins.go:161] Loaded 11 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,PodSecurity,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,CertificateSubjectRestriction,ValidatingAdmissionWebhook,ResourceQuota.
I1221 04:30:57.810111       1 plugins.go:158] Loaded 12 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,MutatingAdmissionWebhook.
I1221 04:30:57.810120       1 plugins.go:161] Loaded 11 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,PodSecurity,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,CertificateSubjectRestriction,ValidatingAdmissionWebhook,ResourceQuota.
I1221 04:30:57.811287       1 shared_informer.go:255] Waiting for caches to sync for node_authorizer
W1221 04:30:57.814318       1 logging.go:59] [core] [Channel #1 SubChannel #2] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W1221 04:30:58.809222       1 logging.go:59] [core] [Channel #3 SubChannel #4] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W1221 04:30:58.811529       1 logging.go:59] [core] [Channel #5 SubChannel #6] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W1221 04:30:58.815086       1 logging.go:59] [core] [Channel #1 SubChannel #2] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W1221 04:30:59.810511       1 logging.go:59] [core] [Channel #3 SubChannel #4] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W1221 04:30:59.813007       1 logging.go:59] [core] [Channel #5 SubChannel #6] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W1221 04:31:00.599596       1 genericapiserver.go:656] Skipping API apiextensions.k8s.io/v1beta1 because it has no resources.
I1221 04:31:00.600606       1 instance.go:261] Using reconciler: lease
I1221 04:31:00.813847       1 instance.go:574] API group "internal.apiserver.k8s.io" is not enabled, skipping.
W1221 04:31:01.180402       1 genericapiserver.go:656] Skipping API authentication.k8s.io/v1beta1 because it has no resources.
W1221 04:31:01.181933       1 genericapiserver.go:656] Skipping API authorization.k8s.io/v1beta1 because it has no resources.
W1221 04:31:01.184779       1 genericapiserver.go:656] Skipping API autoscaling/v2beta1 because it has no resources.
W1221 04:31:01.187705       1 genericapiserver.go:656] Skipping API batch/v1beta1 because it has no resources.
W1221 04:31:01.189100       1 genericapiserver.go:656] Skipping API certificates.k8s.io/v1beta1 because it has no resources.
W1221 04:31:01.190321       1 genericapiserver.go:656] Skipping API coordination.k8s.io/v1beta1 because it has no resources.
W1221 04:31:01.190384       1 genericapiserver.go:656] Skipping API discovery.k8s.io/v1beta1 because it has no resources.
W1221 04:31:01.193593       1 genericapiserver.go:656] Skipping API networking.k8s.io/v1beta1 because it has no resources.
W1221 04:31:01.193635       1 genericapiserver.go:656] Skipping API networking.k8s.io/v1alpha1 because it has no resources.
W1221 04:31:01.195093       1 genericapiserver.go:656] Skipping API node.k8s.io/v1beta1 because it has no resources.
W1221 04:31:01.195130       1 genericapiserver.go:656] Skipping API node.k8s.io/v1alpha1 because it has no resources.
W1221 04:31:01.195163       1 genericapiserver.go:656] Skipping API policy/v1beta1 because it has no resources.
W1221 04:31:01.198589       1 genericapiserver.go:656] Skipping API rbac.authorization.k8s.io/v1beta1 because it has no resources.
W1221 04:31:01.198630       1 genericapiserver.go:656] Skipping API rbac.authorization.k8s.io/v1alpha1 because it has no resources.
W1221 04:31:01.199865       1 genericapiserver.go:656] Skipping API scheduling.k8s.io/v1beta1 because it has no resources.
W1221 04:31:01.199904       1 genericapiserver.go:656] Skipping API scheduling.k8s.io/v1alpha1 because it has no resources.
W1221 04:31:01.203397       1 genericapiserver.go:656] Skipping API storage.k8s.io/v1alpha1 because it has no resources.
W1221 04:31:01.206657       1 genericapiserver.go:656] Skipping API flowcontrol.apiserver.k8s.io/v1alpha1 because it has no resources.
W1221 04:31:01.209923       1 genericapiserver.go:656] Skipping API apps/v1beta2 because it has no resources.
W1221 04:31:01.209965       1 genericapiserver.go:656] Skipping API apps/v1beta1 because it has no resources.
W1221 04:31:01.211525       1 genericapiserver.go:656] Skipping API admissionregistration.k8s.io/v1beta1 because it has no resources.
W1221 04:31:01.212996       1 genericapiserver.go:656] Skipping API events.k8s.io/v1beta1 because it has no resources.
I1221 04:31:01.213826       1 plugins.go:158] Loaded 12 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,MutatingAdmissionWebhook.
I1221 04:31:01.213842       1 plugins.go:161] Loaded 11 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,PodSecurity,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,CertificateSubjectRestriction,ValidatingAdmissionWebhook,ResourceQuota.
W1221 04:31:01.247120       1 genericapiserver.go:656] Skipping API apiregistration.k8s.io/v1beta1 because it has no resources.
I1221 04:31:02.681547       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/etc/kubernetes/pki/front-proxy-ca.crt"
I1221 04:31:02.681842       1 secure_serving.go:210] Serving securely on [::]:6443
I1221 04:31:02.681985       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I1221 04:31:02.681991       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/ca.crt"
I1221 04:31:02.681994       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/etc/kubernetes/pki/apiserver.crt::/etc/kubernetes/pki/apiserver.key"
I1221 04:31:02.685302       1 cluster_authentication_trust_controller.go:440] Starting cluster_authentication_trust_controller controller
I1221 04:31:02.685342       1 shared_informer.go:255] Waiting for caches to sync for cluster_authentication_trust_controller
I1221 04:31:02.686135       1 available_controller.go:491] Starting AvailableConditionController
I1221 04:31:02.686171       1 cache.go:32] Waiting for caches to sync for AvailableConditionController controller
I1221 04:31:02.686304       1 apiservice_controller.go:97] Starting APIServiceRegistrationController
I1221 04:31:02.686337       1 cache.go:32] Waiting for caches to sync for APIServiceRegistrationController controller
I1221 04:31:02.686424       1 controller.go:80] Starting OpenAPI V3 AggregationController
I1221 04:31:02.686473       1 dynamic_serving_content.go:132] "Starting controller" name="aggregator-proxy-cert::/etc/kubernetes/pki/front-proxy-client.crt::/etc/kubernetes/pki/front-proxy-client.key"
I1221 04:31:02.698223       1 controller.go:83] Starting OpenAPI AggregationController
I1221 04:31:02.699264       1 customresource_discovery_controller.go:209] Starting DiscoveryController
I1221 04:31:02.699342       1 apf_controller.go:300] Starting API Priority and Fairness config controller
I1221 04:31:02.699491       1 autoregister_controller.go:141] Starting autoregister controller
I1221 04:31:02.699537       1 cache.go:32] Waiting for caches to sync for autoregister controller
I1221 04:31:02.713479       1 controller.go:85] Starting OpenAPI controller
I1221 04:31:02.713602       1 controller.go:85] Starting OpenAPI V3 controller
I1221 04:31:02.713705       1 naming_controller.go:291] Starting NamingConditionController
I1221 04:31:02.713751       1 establishing_controller.go:76] Starting EstablishingController
I1221 04:31:02.713773       1 nonstructuralschema_controller.go:192] Starting NonStructuralSchemaConditionController
I1221 04:31:02.713785       1 apiapproval_controller.go:186] Starting KubernetesAPIApprovalPolicyConformantConditionController
I1221 04:31:02.713814       1 crd_finalizer.go:266] Starting CRDFinalizer
I1221 04:31:02.713911       1 crdregistration_controller.go:111] Starting crd-autoregister controller
I1221 04:31:02.713917       1 shared_informer.go:255] Waiting for caches to sync for crd-autoregister
I1221 04:31:02.713922       1 shared_informer.go:262] Caches are synced for crd-autoregister
I1221 04:31:02.726101       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/ca.crt"
I1221 04:31:02.728444       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/etc/kubernetes/pki/front-proxy-ca.crt"
I1221 04:31:02.786526       1 cache.go:39] Caches are synced for APIServiceRegistrationController controller
I1221 04:31:02.786627       1 shared_informer.go:262] Caches are synced for cluster_authentication_trust_controller
I1221 04:31:02.786665       1 cache.go:39] Caches are synced for AvailableConditionController controller
I1221 04:31:02.800199       1 cache.go:39] Caches are synced for autoregister controller
I1221 04:31:02.800263       1 apf_controller.go:305] Running API Priority and Fairness config worker
I1221 04:31:02.811708       1 shared_informer.go:262] Caches are synced for node_authorizer
I1221 04:31:02.817257       1 controller.go:616] quota admission added evaluator for: namespaces
I1221 04:31:03.441656       1 controller.go:132] OpenAPI AggregationController: action for item k8s_internal_local_delegation_chain_0000000000: Nothing (removed from the queue).
I1221 04:31:03.706448       1 storage_scheduling.go:95] created PriorityClass system-node-critical with value 2000001000
I1221 04:31:03.712418       1 storage_scheduling.go:95] created PriorityClass system-cluster-critical with value 2000000000
I1221 04:31:03.712440       1 storage_scheduling.go:111] all system priority classes are created successfully or already exist.
I1221 04:31:04.148212       1 controller.go:616] quota admission added evaluator for: roles.rbac.authorization.k8s.io
I1221 04:31:04.181364       1 controller.go:616] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
I1221 04:31:04.238303       1 alloc.go:327] "allocated clusterIPs" service="default/kubernetes" clusterIPs=map[IPv4:10.96.0.1]
W1221 04:31:04.244577       1 lease.go:250] Resetting endpoints for master service "kubernetes" to [172.18.0.2]
I1221 04:31:04.245474       1 controller.go:616] quota admission added evaluator for: endpoints
I1221 04:31:04.248788       1 controller.go:616] quota admission added evaluator for: endpointslices.discovery.k8s.io
I1221 04:31:05.577748       1 controller.go:616] quota admission added evaluator for: serviceaccounts
I1221 04:31:05.584341       1 controller.go:616] quota admission added evaluator for: deployments.apps
I1221 04:31:05.594330       1 alloc.go:327] "allocated clusterIPs" service="kube-system/kube-dns" clusterIPs=map[IPv4:10.96.0.10]
I1221 04:31:05.602661       1 controller.go:616] quota admission added evaluator for: daemonsets.apps
I1221 04:31:05.674948       1 controller.go:616] quota admission added evaluator for: leases.coordination.k8s.io
I1221 04:31:19.993581       1 controller.go:616] quota admission added evaluator for: controllerrevisions.apps
I1221 04:31:20.197312       1 controller.go:616] quota admission added evaluator for: replicasets.apps
I1221 04:32:50.754507       1 alloc.go:327] "allocated clusterIPs" service="kube-system/exposed-kube-dns" clusterIPs=map[IPv4:10.96.101.253]
I1221 04:32:54.345453       1 alloc.go:327] "allocated clusterIPs" service="spire/k8s-workload-registrar" clusterIPs=map[IPv4:10.96.15.224]
I1221 04:32:54.368340       1 alloc.go:327] "allocated clusterIPs" service="spire/spire-server" clusterIPs=map[IPv4:10.96.80.239]
I1221 04:32:54.383433       1 controller.go:616] quota admission added evaluator for: statefulsets.apps
W1221 04:33:13.089572       1 dispatcher.go:185] Failed calling webhook, failing closed k8s-workload-registrar.spire.svc: failed calling webhook "k8s-workload-registrar.spire.svc": failed to call webhook: Post "https://k8s-workload-registrar.spire.svc:443/validate-spiffeid-spiffe-io-v1beta1-spiffeid?timeout=10s": dial tcp 10.96.15.224:443: connect: connection refused
W1221 04:33:13.099926       1 dispatcher.go:185] Failed calling webhook, failing closed k8s-workload-registrar.spire.svc: failed calling webhook "k8s-workload-registrar.spire.svc": failed to call webhook: Post "https://k8s-workload-registrar.spire.svc:443/validate-spiffeid-spiffe-io-v1beta1-spiffeid?timeout=10s": dial tcp 10.96.15.224:443: connect: connection refused
W1221 04:33:13.114285       1 dispatcher.go:185] Failed calling webhook, failing closed k8s-workload-registrar.spire.svc: failed calling webhook "k8s-workload-registrar.spire.svc": failed to call webhook: Post "https://k8s-workload-registrar.spire.svc:443/validate-spiffeid-spiffe-io-v1beta1-spiffeid?timeout=10s": dial tcp 10.96.15.224:443: connect: connection refused
W1221 04:33:13.139093       1 dispatcher.go:185] Failed calling webhook, failing closed k8s-workload-registrar.spire.svc: failed calling webhook "k8s-workload-registrar.spire.svc": failed to call webhook: Post "https://k8s-workload-registrar.spire.svc:443/validate-spiffeid-spiffe-io-v1beta1-spiffeid?timeout=10s": dial tcp 10.96.15.224:443: connect: connection refused
W1221 04:33:13.185028       1 dispatcher.go:185] Failed calling webhook, failing closed k8s-workload-registrar.spire.svc: failed calling webhook "k8s-workload-registrar.spire.svc": failed to call webhook: Post "https://k8s-workload-registrar.spire.svc:443/validate-spiffeid-spiffe-io-v1beta1-spiffeid?timeout=10s": dial tcp 10.96.15.224:443: connect: connection refused
W1221 04:33:13.270131       1 dispatcher.go:185] Failed calling webhook, failing closed k8s-workload-registrar.spire.svc: failed calling webhook "k8s-workload-registrar.spire.svc": failed to call webhook: Post "https://k8s-workload-registrar.spire.svc:443/validate-spiffeid-spiffe-io-v1beta1-spiffeid?timeout=10s": dial tcp 10.96.15.224:443: connect: connection refused
W1221 04:33:13.435302       1 dispatcher.go:185] Failed calling webhook, failing closed k8s-workload-registrar.spire.svc: failed calling webhook "k8s-workload-registrar.spire.svc": failed to call webhook: Post "https://k8s-workload-registrar.spire.svc:443/validate-spiffeid-spiffe-io-v1beta1-spiffeid?timeout=10s": dial tcp 10.96.15.224:443: connect: connection refused
W1221 04:33:13.775624       1 dispatcher.go:185] Failed calling webhook, failing closed k8s-workload-registrar.spire.svc: failed calling webhook "k8s-workload-registrar.spire.svc": failed to call webhook: Post "https://k8s-workload-registrar.spire.svc:443/validate-spiffeid-spiffe-io-v1beta1-spiffeid?timeout=10s": dial tcp 10.96.15.224:443: connect: connection refused
W1221 04:33:14.420998       1 dispatcher.go:185] Failed calling webhook, failing closed k8s-workload-registrar.spire.svc: failed calling webhook "k8s-workload-registrar.spire.svc": failed to call webhook: Post "https://k8s-workload-registrar.spire.svc:443/validate-spiffeid-spiffe-io-v1beta1-spiffeid?timeout=10s": dial tcp 10.96.15.224:443: connect: connection refused
I1221 04:33:15.945233       1 controller.go:616] quota admission added evaluator for: spiffeids.spiffeid.spiffe.io
I1221 04:34:21.361658       1 alloc.go:327] "allocated clusterIPs" service="nsm-system/admission-webhook-svc" clusterIPs=map[IPv4:10.96.208.151]
I1221 04:34:21.380490       1 alloc.go:327] "allocated clusterIPs" service="nsm-system/nsmgr-proxy" clusterIPs=map[IPv4:10.96.40.52]
I1221 04:34:21.403395       1 alloc.go:327] "allocated clusterIPs" service="nsm-system/registry" clusterIPs=map[IPv4:10.96.11.255]
I1221 04:34:21.430333       1 alloc.go:327] "allocated clusterIPs" service="nsm-system/registry-proxy" clusterIPs=map[IPv4:10.96.180.74]
I1221 04:34:57.764814       1 alloc.go:327] "allocated clusterIPs" service="kube-system/metrics-server" clusterIPs=map[IPv4:10.96.253.75]
W1221 04:34:58.997632       1 handler_proxy.go:105] no RequestInfo found in the context
E1221 04:34:58.997775       1 controller.go:116] loading OpenAPI spec for "v1beta1.metrics.k8s.io" failed with: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: service unavailable
, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
I1221 04:34:58.997787       1 controller.go:129] OpenAPI AggregationController: action for item v1beta1.metrics.k8s.io: Rate Limited Requeue.
W1221 04:34:59.008796       1 handler_proxy.go:105] no RequestInfo found in the context
E1221 04:34:59.008833       1 controller.go:113] loading OpenAPI spec for "v1beta1.metrics.k8s.io" failed with: Error, could not get list of group versions for APIService
I1221 04:34:59.008839       1 controller.go:126] OpenAPI AggregationController: action for item v1beta1.metrics.k8s.io: Rate Limited Requeue.
I1221 04:35:54.686938       1 controller.go:616] quota admission added evaluator for: networkserviceendpoints.networkservicemesh.io
W1221 04:35:58.998737       1 handler_proxy.go:105] no RequestInfo found in the context
E1221 04:35:58.998853       1 controller.go:116] loading OpenAPI spec for "v1beta1.metrics.k8s.io" failed with: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: service unavailable
, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
I1221 04:35:58.998862       1 controller.go:129] OpenAPI AggregationController: action for item v1beta1.metrics.k8s.io: Rate Limited Requeue.
W1221 04:35:59.009260       1 handler_proxy.go:105] no RequestInfo found in the context
E1221 04:35:59.009358       1 controller.go:113] loading OpenAPI spec for "v1beta1.metrics.k8s.io" failed with: Error, could not get list of group versions for APIService
I1221 04:35:59.009368       1 controller.go:126] OpenAPI AggregationController: action for item v1beta1.metrics.k8s.io: Rate Limited Requeue.
W1221 04:36:03.738461       1 handler_proxy.go:105] no RequestInfo found in the context
E1221 04:36:03.738551       1 controller.go:113] loading OpenAPI spec for "v1beta1.metrics.k8s.io" failed with: Error, could not get list of group versions for APIService
I1221 04:36:03.738557       1 controller.go:126] OpenAPI AggregationController: action for item v1beta1.metrics.k8s.io: Rate Limited Requeue.
W1221 04:36:03.738579       1 handler_proxy.go:105] no RequestInfo found in the context
E1221 04:36:03.738618       1 controller.go:116] loading OpenAPI spec for "v1beta1.metrics.k8s.io" failed with: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: service unavailable
, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
I1221 04:36:03.739895       1 controller.go:129] OpenAPI AggregationController: action for item v1beta1.metrics.k8s.io: Rate Limited Requeue.
E1221 04:36:08.423066       1 available_controller.go:524] v1beta1.metrics.k8s.io failed with: failing or missing response from https://10.96.253.75:443/apis/metrics.k8s.io/v1beta1: Get "https://10.96.253.75:443/apis/metrics.k8s.io/v1beta1": dial tcp 10.96.253.75:443: connect: connection refused
E1221 04:36:08.423992       1 available_controller.go:524] v1beta1.metrics.k8s.io failed with: failing or missing response from https://10.96.253.75:443/apis/metrics.k8s.io/v1beta1: Get "https://10.96.253.75:443/apis/metrics.k8s.io/v1beta1": dial tcp 10.96.253.75:443: connect: connection refused
E1221 04:36:08.428615       1 available_controller.go:524] v1beta1.metrics.k8s.io failed with: failing or missing response from https://10.96.253.75:443/apis/metrics.k8s.io/v1beta1: Get "https://10.96.253.75:443/apis/metrics.k8s.io/v1beta1": dial tcp 10.96.253.75:443: connect: connection refused
E1221 04:36:08.450377       1 available_controller.go:524] v1beta1.metrics.k8s.io failed with: failing or missing response from https://10.96.253.75:443/apis/metrics.k8s.io/v1beta1: Get "https://10.96.253.75:443/apis/metrics.k8s.io/v1beta1": dial tcp 10.96.253.75:443: connect: connection refused
I1221 05:12:33.254393       1 alloc.go:327] "allocated clusterIPs" service="ns-dns-vl3/vl3-ipam" clusterIPs=map[IPv4:10.96.87.223]
I1221 05:12:56.367411       1 controller.go:616] quota admission added evaluator for: networkservices.networkservicemesh.io
W1221 05:13:10.194401       1 dispatcher.go:174] Failed calling webhook, failing open rev.validation.istio.io: failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": service "istiod" not found
E1221 05:13:10.194467       1 dispatcher.go:181] failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": service "istiod" not found
I1221 05:13:10.194499       1 controller.go:616] quota admission added evaluator for: envoyfilters.networking.istio.io
W1221 05:13:10.205806       1 dispatcher.go:174] Failed calling webhook, failing open rev.validation.istio.io: failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": service "istiod" not found
E1221 05:13:10.205877       1 dispatcher.go:181] failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": service "istiod" not found
W1221 05:13:10.220457       1 dispatcher.go:174] Failed calling webhook, failing open rev.validation.istio.io: failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": service "istiod" not found
E1221 05:13:10.220520       1 dispatcher.go:181] failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": service "istiod" not found
W1221 05:13:10.235880       1 dispatcher.go:174] Failed calling webhook, failing open rev.validation.istio.io: failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": service "istiod" not found
E1221 05:13:10.235909       1 dispatcher.go:181] failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": service "istiod" not found
W1221 05:13:10.269760       1 dispatcher.go:174] Failed calling webhook, failing open rev.validation.istio.io: failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": service "istiod" not found
E1221 05:13:10.269816       1 dispatcher.go:181] failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": service "istiod" not found
W1221 05:13:10.301738       1 dispatcher.go:174] Failed calling webhook, failing open rev.validation.istio.io: failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": service "istiod" not found
E1221 05:13:10.301803       1 dispatcher.go:181] failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": service "istiod" not found
W1221 05:13:10.327827       1 dispatcher.go:174] Failed calling webhook, failing open rev.validation.istio.io: failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": service "istiod" not found
E1221 05:13:10.327879       1 dispatcher.go:181] failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": service "istiod" not found
W1221 05:13:10.360462       1 dispatcher.go:174] Failed calling webhook, failing open rev.validation.istio.io: failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": service "istiod" not found
E1221 05:13:10.360506       1 dispatcher.go:181] failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": service "istiod" not found
I1221 05:13:10.537271       1 controller.go:616] quota admission added evaluator for: poddisruptionbudgets.policy
I1221 05:13:10.631276       1 controller.go:616] quota admission added evaluator for: horizontalpodautoscalers.autoscaling
I1221 05:13:10.676506       1 alloc.go:327] "allocated clusterIPs" service="istio-system/istiod" clusterIPs=map[IPv4:10.96.240.172]
W1221 05:13:37.280091       1 dispatcher.go:174] Failed calling webhook, failing open rev.validation.istio.io: failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": dial tcp 10.96.240.172:443: connect: connection refused
E1221 05:13:37.280150       1 dispatcher.go:181] failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": dial tcp 10.96.240.172:443: connect: connection refused
I1221 05:13:37.280180       1 controller.go:616] quota admission added evaluator for: gateways.networking.istio.io
W1221 05:13:37.312477       1 dispatcher.go:174] Failed calling webhook, failing open rev.validation.istio.io: failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": dial tcp 10.96.240.172:443: connect: connection refused
E1221 05:13:37.312537       1 dispatcher.go:181] failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": dial tcp 10.96.240.172:443: connect: connection refused
W1221 05:13:38.272061       1 dispatcher.go:174] Failed calling webhook, failing open rev.validation.istio.io: failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": dial tcp 10.96.240.172:443: connect: connection refused
E1221 05:13:38.272096       1 dispatcher.go:181] failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": dial tcp 10.96.240.172:443: connect: connection refused
W1221 05:13:38.309103       1 dispatcher.go:174] Failed calling webhook, failing open rev.validation.istio.io: failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": dial tcp 10.96.240.172:443: connect: connection refused
E1221 05:13:38.309160       1 dispatcher.go:181] failed calling webhook "rev.validation.istio.io": failed to call webhook: Post "https://istiod.istio-system.svc:443/validate?timeout=10s": dial tcp 10.96.240.172:443: connect: connection refused
I1221 05:13:45.615893       1 controller.go:616] quota admission added evaluator for: istiooperators.install.istio.io
W1221 05:13:46.327704       1 dispatcher.go:193] rejected by webhook "rev.validation.istio.io": &errors.StatusError{ErrStatus:v1.Status{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ListMeta:v1.ListMeta{SelfLink:"", ResourceVersion:"", Continue:"", RemainingItemCount:(*int64)(nil)}, Status:"Failure", Message:"admission webhook \"rev.validation.istio.io\" denied the request: configuration is invalid: gateway must have at least one server", Reason:"", Details:(*v1.StatusDetails)(nil), Code:400}}
I1221 05:51:41.941759       1 trace.go:205] Trace[97288915]: "Get" url:/api/v1/namespaces/istio-system/configmaps/istio-gateway-deployment-leader,user-agent:pilot-discovery/1.16.0,audit-id:76646861-b953-410a-9e11-4cd4a844b91a,client:10.244.0.15,accept:application/json, */*,protocol:HTTP/2.0 (21-Dec-2022 05:51:41.417) (total time: 507ms):
Trace[97288915]: ---"About to write a response" 502ms (05:51:41.919)
Trace[97288915]: [507.991789ms] [507.991789ms] END
I1221 05:51:41.989569       1 trace.go:205] Trace[1955776767]: "Get" url:/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/kube-scheduler,user-agent:kube-scheduler/v1.25.3 (linux/amd64) kubernetes/434bfd8/leader-election,audit-id:a9fa769b-3a3b-4e41-a469-22de8e1dfa86,client:172.18.0.2,accept:application/vnd.kubernetes.protobuf, */*,protocol:HTTP/2.0 (21-Dec-2022 05:51:41.448) (total time: 540ms):
Trace[1955776767]: ---"About to write a response" 539ms (05:51:41.987)
Trace[1955776767]: [540.842759ms] [540.842759ms] END
I1221 05:51:42.035526       1 trace.go:205] Trace[2009804639]: "Get" url:/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/kube-controller-manager,user-agent:kube-controller-manager/v1.25.3 (linux/amd64) kubernetes/434bfd8/leader-election,audit-id:2be1aa21-47e8-49ff-aba5-31ce3ac946d9,client:172.18.0.2,accept:application/vnd.kubernetes.protobuf, */*,protocol:HTTP/2.0 (21-Dec-2022 05:51:41.406) (total time: 628ms):
Trace[2009804639]: ---"About to write a response" 628ms (05:51:42.035)
Trace[2009804639]: [628.647054ms] [628.647054ms] END
I1221 07:29:49.632872       1 trace.go:205] Trace[1045233040]: "Get" url:/api/v1/namespaces/istio-system/pods/istiod-5d74c58fdd-gfddt/log,user-agent:kubectl/v1.25.2 (darwin/amd64) kubernetes/5835544,audit-id:2c46ab24-9e10-405f-9d28-ec1eda8882e6,client:172.18.0.1,accept:application/json, */*,protocol:HTTP/2.0 (21-Dec-2022 07:29:49.022) (total time: 607ms):
Trace[1045233040]: ---"Writing http response done" 602ms (07:29:49.630)
Trace[1045233040]: [607.639873ms] [607.639873ms] END
==== END logs for container kube-apiserver of pod kube-system/kube-apiserver-kind-1-control-plane ====
